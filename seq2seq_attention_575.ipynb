{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_attention_575.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanakakeitaro/r_d/blob/master/seq2seq_attention_575.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrUyqvX9HllC",
        "colab_type": "code",
        "outputId": "fa98b019-65e5-40a6-8ae6-4620676a26e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQCRIPRSjj3",
        "colab_type": "code",
        "outputId": "8072e958-b3b8-41ca-d5a4-7d675cff9e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My Drive/'俳句&川柳データセット'/marusen575"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/俳句&川柳データセット/marusen575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJBdPFRJpb5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from chainer import Chain, Variable, links, optimizers, optimizer, functions, serializers\n",
        "import chainer\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import random\n",
        "# データセットを分割するモジュールの読み込み\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvOK35no9LxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = np.array([\n",
        "              [0, 0, 0],\n",
        "              [1, 1, 1],\n",
        "              [2, 2, 2]]).astype(np.float32)\n",
        "l = links.EmbedID(W.shape[0], W.shape[1], initialW=W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drnXbfRs-v0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = links.EmbedID(10, 50, ignore_label=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klFkNWeq-cAB",
        "colab_type": "code",
        "outputId": "34f4d1d5-8660-4292-9939-dbd08b9b1d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "x = np.array([2, 5, 1, 3]).astype(np.int32)\n",
        "y = l(x)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[-0.72052014, -0.05138012, -0.27986604, -1.2555176 ,\n",
              "           -0.93823355, -0.9335817 ,  1.4578001 , -0.533532  ,\n",
              "           -0.16433288,  0.44913423, -0.4262043 , -0.0037776 ,\n",
              "           -0.31365454,  0.75423056, -1.6475728 ,  1.5726223 ,\n",
              "           -0.20037477, -0.5077814 ,  1.5955125 , -0.7155665 ,\n",
              "           -0.8140466 ,  0.50452685,  1.0830566 , -0.9062343 ,\n",
              "           -0.20746495,  1.8931264 ,  0.11392874,  1.1904873 ,\n",
              "           -0.8993586 , -0.41180018,  2.8627884 , -1.5355136 ,\n",
              "            1.5619587 , -0.45880258, -0.5258363 ,  0.6606859 ,\n",
              "            2.3301973 , -1.596562  ,  1.1451398 , -0.36461523,\n",
              "           -0.16047572, -1.3636183 , -0.73220277, -0.25376236,\n",
              "           -0.42955297, -2.1224468 , -0.28091738, -0.40797278,\n",
              "            0.746597  ,  0.8466254 ],\n",
              "          [-0.84835565,  1.5131326 ,  0.22177607, -0.5709425 ,\n",
              "            1.3266495 , -0.4504019 ,  0.0102353 , -0.04598566,\n",
              "           -0.9511705 ,  0.4194501 ,  0.3332186 ,  0.11773057,\n",
              "            1.0838457 ,  0.818494  , -0.22686945,  0.73056203,\n",
              "            1.3268304 , -0.736692  , -1.9718479 ,  0.17091563,\n",
              "           -0.8405827 ,  0.18280087,  1.2868165 ,  0.6610638 ,\n",
              "            1.8234794 , -1.9762534 ,  0.8485754 ,  1.280507  ,\n",
              "           -1.1266967 , -3.1198509 ,  0.3293614 , -0.27708313,\n",
              "           -0.31260762,  0.6236481 ,  0.4368486 ,  1.1783795 ,\n",
              "            0.40073216, -0.24679706, -0.12916791,  0.20385142,\n",
              "           -0.19377263,  1.5788853 ,  0.576763  ,  1.3297712 ,\n",
              "            1.1392719 , -0.3232833 ,  0.4530236 ,  0.52396256,\n",
              "            0.09595373, -1.5868224 ],\n",
              "          [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ,  0.        ,  0.        ,\n",
              "            0.        ,  0.        ],\n",
              "          [ 0.06426433, -0.20929833, -0.01428663, -1.5342519 ,\n",
              "           -0.55151343, -1.0619193 , -0.23703137, -0.24533266,\n",
              "           -0.93993074, -0.8962793 ,  0.21969591,  0.41115633,\n",
              "            1.7528864 , -1.7616407 , -1.3637158 ,  1.0286932 ,\n",
              "            0.22192708, -0.5081271 ,  0.13127677,  0.6038149 ,\n",
              "            2.1902888 ,  0.36500907, -0.17009841, -0.32549748,\n",
              "            0.49781913, -1.722163  ,  0.11271448, -1.1037639 ,\n",
              "            1.8278171 , -1.2153916 , -1.5070702 ,  1.0602471 ,\n",
              "            0.59846723,  0.27654028, -0.43019307,  0.04188948,\n",
              "           -0.2132206 , -0.402558  , -0.50636715, -0.91305214,\n",
              "           -0.03542181,  0.05286369,  1.1428086 ,  1.0689918 ,\n",
              "           -1.2739449 , -0.93089974, -1.0302129 , -1.4057075 ,\n",
              "           -0.46927798, -2.219604  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyLFmp3eAK6L",
        "colab_type": "code",
        "outputId": "1dd682f1-22a4-4a0e-a05e-cbaf4cfdcf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up7QVHWwPDXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pickle_load(path):\n",
        "    with open(path, mode='rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        return data\n",
        "kami5_data = np.array(pickle_load('marusen_kami5_list.pickle'))\n",
        "naka7_data = np.array(pickle_load('marusen_naka7_list.pickle'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgdVcHHCOFJh",
        "colab_type": "code",
        "outputId": "ed33695a-b7bd-4950-ba9b-5a5c526a8ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id_to_word = pickle_load('id_to_word_marusen575.pickle')\n",
        "word_to_id = pickle_load('word_to_id_marusen575.pickle')\n",
        "print(len(id_to_word), len(word_to_id))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20334 20334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK--4zpaJgt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# naka7リストの末尾に<eos>を追加\n",
        "[l.append(1) for l in naka7_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yynTHLYcM-JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reversedリストの作成\n",
        "kami5_reversed_data = [list(reversed(l)) for l in kami5_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5mI-EVMOhJ",
        "colab_type": "code",
        "outputId": "9b3176ea-cbf8-46e8-c648-2d73c85b5368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# enc_wordsとdec_wordsの準備\n",
        "data = np.array([[i, j] for i, j in zip(kami5_data, naka7_data)])\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[list([3, 4]), list([5, 6, 7, 1])],\n",
              "       [list([9, 10]), list([11, 12, 13, 1])],\n",
              "       [list([15, 13]), list([16, 17, 18, 1])],\n",
              "       ...,\n",
              "       [list([98]), list([76, 18, 1327, 4, 1])],\n",
              "       [list([263, 18]), list([4140, 39, 1334, 4, 1])],\n",
              "       [list([5618]), list([20332, 20333, 41, 1])]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79hl6dfzPLKG",
        "colab_type": "code",
        "outputId": "bfa559c1-d636-4581-935b-64eba4e30ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "x_train, x_test = train_test_split(data, test_size=0.2, random_state=0)\n",
        "print(x_train, x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[list([251, 13, 5033]) list([79, 33, 295, 18, 1])]\n",
            " [list([888, 1280, 18]) list([1281, 1282, 1])]\n",
            " [list([14941, 13]) list([1200, 41, 19834, 43, 1])]\n",
            " ...\n",
            " [list([8499, 13]) list([639, 7, 10081, 1])]\n",
            " [list([12338]) list([14725, 41, 1])]\n",
            " [list([4332]) list([2377, 33, 799, 4, 1])]] (14654, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs-rbCeRJ7Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_Encoder(Chain):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        \"\"\"\n",
        "        クラスの初期化\n",
        "        :param vocab_size: 使われる単語の種類数（語彙数）\n",
        "        :param embed_size: 単語をベクトル表現した際のサイズ\n",
        "        :param hidden_size: 中間層のサイズ\n",
        "        \"\"\"\n",
        "        super(LSTM_Encoder, self).__init__(\n",
        "            # 単語を単語ベクトルに変換する層\n",
        "            xe = links.EmbedID(vocab_size, embed_size, ignore_label=-1),\n",
        "            # 単語ベクトルを隠れ層の4倍のサイズのベクトルに変換する層\n",
        "            eh = links.Linear(embed_size, 4 * hidden_size),\n",
        "            # 出力された中間層を4倍のサイズに変換するための層\n",
        "            hh = links.Linear(hidden_size, 4 * hidden_size)\n",
        "        )\n",
        "\n",
        "    def __call__(self, x, c, h):\n",
        "        \"\"\"\n",
        "        Encoderの計算\n",
        "        :param x: one-hotなベクトル\n",
        "        :param c: 内部メモリ\n",
        "        :param h: 隠れ層\n",
        "        :return: 次の内部メモリ、次の隠れ層\n",
        "        \"\"\"\n",
        "        # xeで単語ベクトルに変換して、そのベクトルをtanhで活性化\n",
        "        e = functions.tanh(self.xe(x))\n",
        "        # 前の内部メモリの値cと単語ベクトルの4倍サイズ+中間層の4倍サイズを入力\n",
        "        return functions.lstm(c, self.eh(e) + self.hh(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s8q71km42Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Att_LSTM_Decoder(Chain):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        \"\"\"\n",
        "        Attention ModelのためのDecoderのインスタンス化\n",
        "        :param vocab_size: 語彙数\n",
        "        :param embed_size: 単語ベクトルのサイズ\n",
        "        :param hidden_size: 隠れ層のサイズ\n",
        "        \"\"\"\n",
        "        super(Att_LSTM_Decoder, self).__init__(\n",
        "            # 単語を単語ベクトルに変換する層\n",
        "            ye = links.EmbedID(vocab_size, embed_size, ignore_label = -1),\n",
        "            # 単語ベクトルを隠れ層の4倍のサイズのベクトルに変換する層\n",
        "            eh = links.Linear(embed_size, 4 * hidden_size),\n",
        "            # Decoderの中間ベクトルを隠れ層の4倍のサイズのベクトルに変換する層\n",
        "            hh = links.Linear(hidden_size, 4 * hidden_size),\n",
        "            # 順向きEncoderの中間ベクトルの加重平均を隠れ層の4倍のサイズのベクトルに変換する層\n",
        "            fh = links.Linear(hidden_size, 4 * hidden_size),\n",
        "            # 順向きEncoderの中間ベクトルの加重平均を隠れ層の4倍のサイズのベクトルに変換する層\n",
        "            bh = links.Linear(hidden_size, 4 * hidden_size),\n",
        "            # 隠れ層サイズのベクトルを単語ベクトルのサイズに変換する層\n",
        "            he = links.Linear(hidden_size, embed_size),\n",
        "            # 単語ベクトルを語彙数サイズのベクトルに変換する層\n",
        "            ey = links.Linear(embed_size, vocab_size)\n",
        "        )\n",
        "    \n",
        "    def __call__(self, y, c, h, f, b):\n",
        "        \"\"\"\n",
        "        Decoderの計算\n",
        "        :param y: Decoderに入力する単語\n",
        "        :param c: 内部メモリ\n",
        "        :param h: Decoderの中間ベクトル\n",
        "        :param f: Attention Modelで計算された順向きEncoderの加重平均\n",
        "        :param b: Attention Modelで計算された逆向きEncoderの加重平均\n",
        "        :return: 語彙数サイズのベクトル、更新された内部メモリ、更新された中間ベクトル\n",
        "        \"\"\"\n",
        "        # 単語を単語ベクトルに変換\n",
        "        e = functions.tanh(self.ye(y))\n",
        "        # 単語ベクトル、Decoderの中間ベクトル、順向きEncoderのAttention、逆向きEncoderのAttentionを使ってLSTM\n",
        "        c, h = functions.lstm(c, self.eh(e) + self.hh(h) + self.fh(f) + self.bh(b))\n",
        "        # LSTMから出力された中間ベクトルを語彙数サイズのベクトルに変換する\n",
        "        t = self.ey(functions.tanh(self.he(h)))\n",
        "        return t, c, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1va7JUuZoVoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(Chain):\n",
        "    def __init__(self, hidden_size, flag_gpu):\n",
        "          \"\"\"\n",
        "          Attentionのインスタンス化\n",
        "          :param hidden_size: 隠れ層のサイズ\n",
        "          :param flag_gpu: GPUを使うかどうか\n",
        "          \"\"\"\n",
        "          super(Attention, self).__init__(\n",
        "              # 順向きのEncoderの中間ベクトルを隠れ層サイズのベクトルに変換する線形結合層\n",
        "              fh = links.Linear(hidden_size, hidden_size),\n",
        "              # 逆向きのEncoderの中間ベクトルを隠れ層サイズのベクトルに変換する線形結合層\n",
        "              bh = links.Linear(hidden_size, hidden_size),\n",
        "              # Decoderの中間ベクトルを隠れ層サイズのベクトルに変換する線形結合層\n",
        "              hh = links.Linear(hidden_size, hidden_size),\n",
        "              # 隠れ層サイズのベクトルをスカラーに変換するための線形結合層\n",
        "              hw = links.Linear(hidden_size, 1)\n",
        "              )\n",
        "          # 隠れ層のサイズを記憶\n",
        "          self.hidden_size = hidden_size\n",
        "          # GPUを使う場合はcupyを使わないときはnumpyを使う\n",
        "          if flag_gpu:\n",
        "              self.ARR = cuda.cupy\n",
        "          else:\n",
        "              self.ARR = np\n",
        "\n",
        "    def __call__(self, fs, bs, h):\n",
        "          \"\"\"\n",
        "          Attentionの計算\n",
        "          :param fs: 順向きのEncoderの中間ベクトルが記録されたリスト\n",
        "          :param bs: 逆向きのEncoderの中間ベクトルが記録されたリスト\n",
        "          :param h: Decoderで出力された中間ベクトル\n",
        "          :return: N\n",
        "          \"\"\"\n",
        "          #ミニバッチのサイズを記憶\n",
        "          batch_size = h.data.shape[0]\n",
        "          # ウェイトを記録するためのリストの初期化\n",
        "          ws = []\n",
        "          # ウェイトの合計値を計算するための値を初期化\n",
        "          sum_w = Variable(self.ARR.zeros((batch_size, 1), dtype='float32'))\n",
        "          # Encoderの中間ベクトルとDecoderの中間ベクトルを使ってウェイトの計算\n",
        "          for f, b in zip(fs, bs):\n",
        "              # 順向きEncoderの中間ベクトル、逆向きEncoderの中間ベクトル、Decoderの中間ベクトルを使ってウェイトの計算\n",
        "              w = functions.tanh(self.fh(f) + self.bh(b) + self.hh(h))\n",
        "              # softmax関数を使って正規化する\n",
        "              w = functions.exp(self.hw(w))\n",
        "              # 計算したウェイトを記録\n",
        "              ws.append(w)\n",
        "              sum_w += w\n",
        "          # 出力する加重平均ベクトルの初期化\n",
        "          att_f = Variable(self.ARR.zeros((batch_size, self.hidden_size), dtype = 'float32'))\n",
        "          att_b = Variable(self.ARR.zeros((batch_size, self.hidden_size), dtype = 'float32'))\n",
        "          for f, b, w in zip (fs, bs, ws):\n",
        "              # ウェイトの和が1になるように正規化\n",
        "              w /= sum_w\n",
        "              # ウェイト * Encoderの中間ベクトルを出力するベクトルに足していく\n",
        "              att_f += functions.reshape(functions.batch_matmul(f, w), (batch_size, self.hidden_size))\n",
        "              att_b += functions.reshape(functions.batch_matmul(b, w), (batch_size, self.hidden_size))\n",
        "          return att_f, att_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtIibpXHIlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Att_Seq2Seq(Chain):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, batch_size, flag_gpu = True):\n",
        "        \"\"\"\n",
        "        Seq2Seq + Attentionのインスタンス化\n",
        "        :param vocab_size: 語彙数のサイズ\n",
        "        :param embed_size: 単語ベクトルのサイズ\n",
        "        :param hidden_size: 隠れ層のサイズ\n",
        "        :param batch_size: ミニバッチのサイズ\n",
        "        :param flag_gpu: GPUを使うかどうか\n",
        "        \"\"\"\n",
        "        super(Att_Seq2Seq, self).__init__(\n",
        "            # 順向きのEncoder\n",
        "            f_encoder = LSTM_Encoder(vocab_size, embed_size, hidden_size),\n",
        "            # 逆向きのEncoder\n",
        "            b_encoder = LSTM_Encoder(vocab_size, embed_size, hidden_size),\n",
        "            # Attention Model\n",
        "            attention = Attention(hidden_size, flag_gpu),\n",
        "            # Decoder\n",
        "            decoder = Att_LSTM_Decoder(vocab_size, embed_size, hidden_size)\n",
        "        )\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # GPUを使うときはcupy、使わないときはnumpy\n",
        "        if flag_gpu:\n",
        "            self.ARR = cuda.cupy\n",
        "        else:\n",
        "            self.ARR = np\n",
        "\n",
        "        # 順向きのEncoderの中間ベクトル、逆向きのEncoderの中間ベクトルを保存するためのリストを初期化\n",
        "        self.fs = []\n",
        "        self.bs = []\n",
        "\n",
        "    def encode(self, words):\n",
        "        \"\"\"\n",
        "        Encoderの計算\n",
        "        :param words: 入力で使用する単語記録されたリスト\n",
        "        :return: \n",
        "        \"\"\"\n",
        "        # 内部メモリ、中間ベクトルの初期化\n",
        "        c = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        h = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        # まずは順向きのEncoderの計算\n",
        "        for w in words:\n",
        "            c, h = self.f_encoder(w, c, h)\n",
        "            # 計算された中間ベクトルを記録\n",
        "            self.fs.append(h)\n",
        "\n",
        "        # 内部メモリ、中間ベクトルの初期化\n",
        "        c = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        h = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        # 逆向きのEncoderの計算\n",
        "        for w in reversed(words):\n",
        "            c, h = self.b_encoder(w, c, h)\n",
        "            # 計算された中間ベクトルを記録 \n",
        "            self.bs.insert(0, h)\n",
        "\n",
        "        # 内部メモリ、中間ベクトルの初期化\n",
        "        self.c = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        self.h = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "\n",
        "    def decode(self, w):\n",
        "        \"\"\"\n",
        "        Decoderの計算\n",
        "        :param w: Decoderで入力する単語\n",
        "        :return: 予測単語\n",
        "        \"\"\"\n",
        "        # Attention Modelを使ってEncoderの中間層の加重平均を計算\n",
        "        att_f, att_b = self.attention(self.fs, self.bs, self.h)\n",
        "        # Decoderの中間ベクトル、順向きのAttention、逆向きのAttentionを使って次の中間ベクトル、内部メモリ、予測単語の計算    \n",
        "        t, self.c, self.h = self.decoder(w, self.c, self.h, att_f, att_b)\n",
        "        return t\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        インスタンス変数を初期化する\n",
        "        :return: \n",
        "        \"\"\"\n",
        "        # 内部メモリ、中間ベクトルの初期化\n",
        "        self.c = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        self.h = Variable(self.ARR.zeros((self.batch_size, self.hidden_size), dtype = 'float32'))\n",
        "        # Encoderの中間ベクトルを記録するリストの初期化\n",
        "        self.fs = []\n",
        "        self.bs = []\n",
        "        # 勾配の初期化\n",
        "        self.cleargrads()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W5A-08AzNla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(enc_words, dec_words, model, ARR):\n",
        "    batch_size = len(enc_words[0])\n",
        "    model.reset()\n",
        "    enc_words = [Variable(ARR.array(row, dtype='int32')) for row in enc_words]\n",
        "    model.encode(enc_words)\n",
        "    # 損失の初期化\n",
        "    loss = Variable(ARR.zeros((), dtype='float32'))\n",
        "    # 精度の初期化\n",
        "    acc = Variable(ARR.zeros((), dtype='float32'))\n",
        "    # <eos>をデコーダーに読み込ませる ②\n",
        "    t = Variable(ARR.array([0 for _ in range(batch_size)], dtype='int32'))\n",
        "    # デコーダーの計算\n",
        "    for w in dec_words:\n",
        "        # 1単語ずつをデコードする ③\n",
        "        y = model.decode(t)\n",
        "        # 正解単語をVariable型に変換\n",
        "        t = Variable(ARR.array(w, dtype='int32'))\n",
        "        # 正解単語と予測単語を照らし合わせて損失を計算 ④\n",
        "        loss += functions.softmax_cross_entropy(y, t)\n",
        "        acc += functions.accuracy(y, t)\n",
        "    return loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNOGrnGwFbLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainの関数\n",
        "def make_minibatch(minibatch):\n",
        "    # enc_wordsの作成\n",
        "    enc_words = [row[0] for row in minibatch]\n",
        "    enc_max = np.max([len(row) for row in enc_words])\n",
        "    enc_words = np.array([[-1]*(enc_max - len(row)) + row for row in enc_words], dtype='int32')\n",
        "    enc_words = enc_words.T\n",
        "    # dec_wordsの作成\n",
        "    dec_words = [row[1] for row in minibatch]\n",
        "    dec_max = np.max([len(row) for row in dec_words])\n",
        "    dec_words = np.array([row + [-1]*(dec_max - len(row)) for row in dec_words], dtype='int32')\n",
        "    dec_words = dec_words.T\n",
        "    return enc_words, dec_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NObUW3fKsUmJ",
        "colab_type": "code",
        "outputId": "166cc64a-8580-4ce7-a6b4-03c388b1dc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd marusen575_not_reversed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/俳句&川柳データセット/marusen575/marusen575_not_reversed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xoTbxeFb7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(data):\n",
        "    # 語彙数の確認\n",
        "    # モデルのインスタンス化\n",
        "    model = Att_Seq2Seq(\n",
        "                       vocab_size=vocab_size,\n",
        "                       embed_size=EMBED_SIZE,\n",
        "                       hidden_size=HIDDEN_SIZE,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       flag_gpu=FLAG_GPU)\n",
        "    # モデルの初期化\n",
        "    model.reset()\n",
        "    \n",
        "    # GPUを使うかどうか決める\n",
        "    if FLAG_GPU:\n",
        "        ARR = cupy\n",
        "        # モデルをGPUのメモリに入れる\n",
        "        #cuda.get_device(0).use()\n",
        "        model.to_gpu(0)\n",
        "    else:\n",
        "        ARR = np\n",
        "    loss_list = []\n",
        "    acc_list = []\n",
        "    # 学習開始\n",
        "    for epoch in range(EPOCH_NUM):\n",
        "        # エポックごとの処理時間計測のためにtime.time()を取得\n",
        "        start = time.time()\n",
        "        # エポックごとにoptimizerの初期化\n",
        "        opt = optimizers.Adam()\n",
        "        # モデルをoptimizerにセット\n",
        "        opt.setup(model)\n",
        "        # 勾配が大きすぎる場合に調整する\n",
        "        opt.add_hook(optimizer.GradientClipping(5))\n",
        "\n",
        "        # データのシャッフル\n",
        "        xr = random.sample(list(data), len(data))\n",
        "        for num in range(len(data)//BATCH_SIZE):\n",
        "                minibatch = data[num*BATCH_SIZE: (num+1)*BATCH_SIZE]\n",
        "                # print('minibatch\\n' + str(minibatch))\n",
        "                # 読み込み用のデータ作成\n",
        "                enc_words, dec_words = make_minibatch(minibatch)\n",
        "                # modelのリセット\n",
        "                model.reset()\n",
        "                # 順伝播で損失の計算\n",
        "                total_loss, acc = forward(\n",
        "                                         enc_words=enc_words,\n",
        "                                         dec_words=dec_words,\n",
        "                                         model=model,\n",
        "                                         ARR=ARR)\n",
        "                loss_list.append(total_loss)\n",
        "                acc_list.append(acc)\n",
        "                # 学習\n",
        "                # 誤差逆伝播で勾配の計算\n",
        "                total_loss.backward()\n",
        "                # 計算した勾配を使ってネットワークを更新\n",
        "                opt.update()\n",
        "                # 記録された勾配を初期化する\n",
        "                opt.use_cleargrads(use=False)\n",
        "        elapsed_time = (time.time() - start) / 60.0\n",
        "        print ('Epoch:{}\\ttotal loss:{}\\ttotal_accuracy:{}\\ttime:{}'.format(epoch+1, total_loss, acc, elapsed_time))\n",
        "        outputpath = OUTPUT_PATH%(EMBED_SIZE, HIDDEN_SIZE, BATCH_SIZE, epoch+1)    \n",
        "        # エポックごとにモデルの保存\n",
        "        serializers.save_npz(outputpath, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-GY1QMlOxx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAG_GPU = False\n",
        "OUTPUT_PATH = 'marusen575_not_reversed_EMBED%s_HIDDEN%s_BATCH%s_EPOCH%s.weights'\n",
        "vocab_size = len(id_to_word)\n",
        "EMBED_SIZE = 300\n",
        "HIDDEN_SIZE = 150\n",
        "BATCH_SIZE = 128\n",
        "EPOCH_NUM = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mi_51KRyNi6",
        "colab_type": "text"
      },
      "source": [
        "1~30エポック"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSFdEuyRQi4X",
        "colab_type": "code",
        "outputId": "04f6faae-ad3d-4712-b788-1a552a00900a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "print ('開始: ')\n",
        "\n",
        "train(x_train)\n",
        "\n",
        "print ('終了: ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "開始: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40fce647cf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'開始: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'終了: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BMpT5qG85uW",
        "colab_type": "text"
      },
      "source": [
        "31〜50エポック"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYTCChGwsb6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('開始: ')\n",
        "\n",
        "train(x_train)\n",
        "\n",
        "print ('終了: ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5hM2P1iRdkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_test(enc_words, model, ARR):\n",
        "    ret = []\n",
        "    model.reset()\n",
        "    enc_words = [Variable(ARR.array(row, dtype='int32')) for row in enc_words]\n",
        "    model.encode(enc_words)\n",
        "    t = Variable(ARR.array([0], dtype='int32'))\n",
        "    counter = 0\n",
        "    while counter < 50:\n",
        "        y = model.decode(t)\n",
        "        # 次の単語のindexを返す\n",
        "        label = y.data.argmax()\n",
        "        ret.append(label)\n",
        "        t = Variable(ARR.array([label], dtype='int32'))\n",
        "        counter += 1\n",
        "        if label == 1:\n",
        "            counter = 50\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoQU1J5FpZym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = Att_Seq2Seq(vocab_size,\n",
        "                       embed_size=EMBED_SIZE,\n",
        "                       hidden_size=HIDDEN_SIZE,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       flag_gpu=FLAG_GPU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKj7-nGppMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "serializers.load_npz('marusen575_EMBED300_HIDDEN150_BATCH128_EPOCH60.weights', loaded_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKu0A4CXW55i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre(train_or_test_list):\n",
        "    a = [[x] for x in train_or_test_list]\n",
        "    a = np.array(a)\n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D79vQtQavJVa",
        "colab_type": "code",
        "outputId": "18802b21-42ca-4676-931f-d93494fe153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/俳句&川柳データセット/marusen575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGVM-mBUqj9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_to_word = pickle_load('id_to_word_marusen575.pickle')\n",
        "word_to_id = pickle_load('word_to_id_marusen575.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th-cPo9wMNDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def id_list_to_senryu(id_list):\n",
        "    ai_senryu_wordlist = []\n",
        "    for each_id in id_list:\n",
        "        ai_senryu_wordlist.append(id_to_word[each_id])\n",
        "    ai_senryu = ''.join(ai_senryu_wordlist)\n",
        "    return ai_senryu\n",
        "\n",
        "def word_to_encode_id(word_list):\n",
        "    word_list_to_id = []\n",
        "    for each_word in word_list:\n",
        "        if each_word not in word_to_id:\n",
        "            each_word = '<unknown>'\n",
        "            word_list_to_id.append(word_to_id[each_word])\n",
        "        else:\n",
        "            word_list_to_id.append(word_to_id[each_word])\n",
        "        a = [[x] for x in word_list_to_id]\n",
        "    b = list(reversed(a))\n",
        "    b = np.array(b)\n",
        "    return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouOO9YKJuU-b",
        "colab_type": "code",
        "outputId": "7554a5dc-ddbe-4fa0-f194-a7fd99f7c462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "i = 51\n",
        "encode_id = pre(x_test[i][0])\n",
        "print(encode_id)\n",
        "print(id_list_to_senryu(x_test[i][0]))\n",
        "id_list_to_senryu(list(reversed(x_test[i][0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   18]\n",
            " [ 2664]\n",
            " [15280]]\n",
            "に品所持\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'所持品に'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rJ4TwBmqGYK",
        "colab_type": "code",
        "outputId": "47b90011-419c-41d5-eb2e-6dabf8e917ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ai_senryu_id = forward_test(encode_id, loaded_model, np)\n",
        "answer_id = list(x_test[i][1])\n",
        "print(\"推論id：\" + str(ai_senryu_id))\n",
        "print(\"正解id：\" + str(answer_id))\n",
        "del ai_senryu_id[-1]\n",
        "del answer_id[-1]\n",
        "print(id_list_to_senryu(ai_senryu_id))\n",
        "print(id_list_to_senryu(answer_id))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "推論id：[23, 1424, 208, 56, 1]\n",
            "正解id：[425, 41, 2328, 1]\n",
            "だけどんよ\n",
            "名前を付ける\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw2A2OaMJzSZ",
        "colab_type": "text"
      },
      "source": [
        "#ユーザーの入力フェーズ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eLOS-isCG01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOYBX2qnLMK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxV-PkjWSW2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjGHGpzsEc0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import io,sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgHuygURSZLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,shell=True).communicate()[0]).decode('utf-8')\n",
        "m=MeCab.Tagger(\"-d {0}\".format(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzFa325cjxFo",
        "colab_type": "code",
        "outputId": "5f8919e0-a5cd-4151-81db-deac7185fa24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "val = input('一句の5音を入れてください：')\n",
        "val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "一句の5音を入れてください：スマホとね\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'スマホとね'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37l-4MZ-DDMs",
        "colab_type": "code",
        "outputId": "c198f810-658c-4532-91e4-3e4497d5c4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "clean_i = re.sub(re.compile('[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％]'), '', val) # 記号の削除\n",
        "sentence = clean_i.replace(\"　\", \"\").replace(\" \", \"\") # スペースの消去\n",
        "node = m.parseToNode(sentence).next #解析してノードに変換\n",
        "\n",
        "word_list = []\n",
        "while node.next: #nodeがfalseになるまで\n",
        "    word_list.append(node.surface)\n",
        "    node = node.next #次の要素に移動（末尾の場合はfalseになる）\n",
        "word_list\n",
        "\n",
        "index = [i for i in word_list]\n",
        "new_encode_id = word_to_encode_id(index)\n",
        "print(new_encode_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   6]\n",
            " [1043]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_EBQ4g0V4Bs",
        "colab_type": "code",
        "outputId": "eafbe560-bb62-4cf5-9af6-39faaaca4f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ai_senryu_id = forward_test(new_encode_id, loaded_model, np)\n",
        "del ai_senryu_id[-1]\n",
        "print(id_list_to_senryu(ai_senryu_id))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "一度命で<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIIAGkjPWf3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}