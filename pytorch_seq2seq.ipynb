{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14rDmB4mwLP9ONA1iLd-puDLsTW1hWs_x",
      "authorship_tag": "ABX9TyNgMNxAgmhLUJ4jn1qV4lZ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanakakeitaro/r_d/blob/master/pytorch_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhsE78yOB0pI",
        "colab_type": "code",
        "outputId": "90e98eb9-92eb-4da8-fa69-6c954dec1cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSAXIDSx0q-M",
        "colab_type": "code",
        "outputId": "7b57c3a8-b6fe-4fc2-db01-b30d88928c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/marusen575"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/103/marusen575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGiBWP3b3q6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def pickle_load(path):\n",
        "    with open(path, mode='rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        return data\n",
        "kami5_data = pickle_load('marusen_kami5_list.pickle')\n",
        "naka7_data = pickle_load('marusen_naka7_list.pickle')\n",
        "\n",
        "id_to_word = pickle_load('id_to_word_marusen575.pickle')\n",
        "word_to_id = pickle_load('word_to_id_marusen575.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2t3gBScvRpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 長さを5に合わせるため、2を末尾に加えてパディング\n",
        "index = 0\n",
        "for w in kami5_data:\n",
        "    while len(w) < 5:\n",
        "        w.append(2)\n",
        "    kami5_data[index] = w\n",
        "    index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t4JRwxx4bpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 先頭に<bos>, 末尾に<eos>を加える\n",
        "[l.insert(0, 0) for l in naka7_data]\n",
        "[l.append(1) for l in naka7_data]\n",
        "\n",
        "# 長さを9に合わせるため、2を末尾に加えてパディング\n",
        "index = 0\n",
        "for w in naka7_data:\n",
        "    while len(w) < 9:\n",
        "        w.append(2)\n",
        "    naka7_data[index] = w\n",
        "    index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I3dtTGXAlNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# train : test = 8 : 2 にデータをわける\n",
        "train_5, test_5, train_7, test_7 = train_test_split(kami5_data, naka7_data, test_size= 0.2, random_state=0)\n",
        "\n",
        "# データをバッチ化するための関数\n",
        "def train2batch(input_data, output_data, batch_size=100):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    input_shuffle, output_shuffle = shuffle(input_data, output_data)\n",
        "    for i in range(0, len(input_data), batch_size):\n",
        "      input_batch.append(input_shuffle[i:i+batch_size])\n",
        "      output_batch.append(output_shuffle[i:i+batch_size])\n",
        "    return input_batch, output_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v394Q_QKm1BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "embedding_dim = 50\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word_to_id)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eViHQqzXHK2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, )\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, indices):\n",
        "        embedding = self.word_embeddings(indices)\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        _, state = self.gru(embedding, torch.zeros(1, self.batch_size, self.hidden_dim, device=device))\n",
        "        \n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWxGzED_bYgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, )\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, index, state):\n",
        "        embedding = self.word_embeddings(index)\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        gruout, state = self.gru(embedding, state)\n",
        "        output = self.output(gruout)\n",
        "        return output, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXt4XpKEl1WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU使えるように\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
        "\n",
        "# 損失関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07qq8nDumWoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "batch_size = 100\n",
        "def train2batch(data, target, batch_size=100):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    input_shuffle, output_shuffle = shuffle(data, target)\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        input_batch.append(input_shuffle[i:i+batch_size])\n",
        "        output_batch.append(output_shuffle[i:i+batch_size])\n",
        "    input_batch.pop(-1)\n",
        "    return input_batch, output_batch\n",
        "\n",
        "def get_current_time():\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08U2AsD93gMJ",
        "colab_type": "code",
        "outputId": "2ea95281-bba1-432c-dea9-935251073087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print(\"Training…\")\n",
        "n_epoch = 100\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    input_batch, output_batch = train2batch(train_5, train_7)\n",
        "    for i in range(len(input_batch)):\n",
        "        # 勾配の初期化\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        # データをテンソルに変換\n",
        "        inputs = torch.tensor(input_batch[i], device=device)\n",
        "        outputs = torch.tensor(output_batch[i], device=device)\n",
        "        # Encoderの順伝播\n",
        "        encoder_hidden = encoder(inputs)\n",
        "        # Decoderで使うデータはoutput_tensorを１つずらしたものを使う\n",
        "        # Decoderのインプットとするデータ\n",
        "        source = outputs[:, :-1]\n",
        "        # Decoderの教師データ\n",
        "        # 生成開始を表す\"<bos>\"を削っている\n",
        "        target = outputs[:, 1:]\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # Forward batch of sequences through decoder one time step at a time\n",
        "        loss = 0\n",
        "        for i in range(source.size(1)):\n",
        "            decoder_output, decoder_hidden = decoder(source[:, i], decoder_hidden)\n",
        "            decoder_output = torch.squeeze(decoder_output)\n",
        "            loss += criterion(decoder_output, target[:, i])\n",
        "        \n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "\n",
        "        # パラメータ更新\n",
        "        # Encoder、Decoder両方学習\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(get_current_time(), \"Epoch %d: %.2f\" % (epoch, loss.item()))    \n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "        torch.save({\n",
        "            'encoder_model': encoder.state_dict(),\n",
        "            'decoder_model': decoder.state_dict(),\n",
        "        }, model_name)\n",
        "        print(\"Saving the checkpoint...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training…\n",
            "2020-05-18 14:24:04 Epoch 10: 17.67\n",
            "Saving the checkpoint...\n",
            "2020-05-18 14:36:34 Epoch 20: 12.52\n",
            "Saving the checkpoint...\n",
            "2020-05-18 14:49:04 Epoch 30: 7.30\n",
            "Saving the checkpoint...\n",
            "2020-05-18 15:01:29 Epoch 40: 4.73\n",
            "Saving the checkpoint...\n",
            "2020-05-18 15:13:58 Epoch 50: 3.18\n",
            "Saving the checkpoint...\n",
            "2020-05-18 15:26:25 Epoch 60: 2.32\n",
            "Saving the checkpoint...\n",
            "2020-05-18 15:38:51 Epoch 70: 1.69\n",
            "Saving the checkpoint...\n",
            "2020-05-18 15:51:12 Epoch 80: 1.31\n",
            "Saving the checkpoint...\n",
            "2020-05-18 16:03:35 Epoch 90: 1.14\n",
            "Saving the checkpoint...\n",
            "2020-05-18 16:15:54 Epoch 100: 1.26\n",
            "Saving the checkpoint...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDIBbfLhrtKs",
        "colab_type": "code",
        "outputId": "e5ee100e-51c9-4fc4-c84b-bfdef09d3d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "\n",
        "for epoch in range(10, 101, 10):\n",
        "    model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "    checkpoint = torch.load(model_name)\n",
        "    encoder.load_state_dict(checkpoint[\"encoder_model\"])\n",
        "    decoder.load_state_dict(checkpoint[\"decoder_model\"])\n",
        "\n",
        "    print(\"Checkpoint {:>3d}\".format(epoch))\n",
        "    print(\"-\"*30)\n",
        "    accuracy = 0\n",
        "    i = 1\n",
        "    input_5 = test_5[:i]\n",
        "    answer_7 = test_7[:i]\n",
        "    with torch.no_grad():\n",
        "        for x_5, y_7 in zip(input_5, answer_7):\n",
        "            pri5 = [id_to_word[i] for i in x_5 if i != 2]\n",
        "            print(pri5)\n",
        "            # テンソルに変換\n",
        "            input_tensor = torch.tensor([x_5], device=device)\n",
        "            # encoderは隠れ状態を返す\n",
        "            state = encoder(input_tensor)\n",
        "            # 変数tokenいらないけどわかりやすさのために\n",
        "            token = '<bos>'\n",
        "            predict_7 = [word_to_id[token]]\n",
        "            # 推論\n",
        "            for _ in range(9):\n",
        "                index = word_to_id[token]\n",
        "                input_tensor = torch.tensor([index], device=device)\n",
        "                output, state = decoder(input_tensor, state)\n",
        "                # 配列の最大値のインデックスを返す\n",
        "                prob = F.softmax(torch.squeeze(output))\n",
        "                ind = torch.argsort(prob.cpu().detach(), descending=True)\n",
        "                print(ind)\n",
        "                index = torch.argmax(prob.cpu().detach()).item()\n",
        "                print(index)\n",
        "                # 次のword候補をtokenに代入\n",
        "                token = id_to_word[index]\n",
        "                predict_7.append(index)\n",
        "            # accuracyを足していく\n",
        "            answer = [id_to_word[i] for i in y_7 if i != 2]\n",
        "            predict = [id_to_word[i] for i in predict_7 if i != 2]\n",
        "            print(answer, predict)\n",
        "            flag = [\"F\", \"T\"][answer == predict]\n",
        "            if flag == \"T\":\n",
        "                accuracy += 1\n",
        "    print(\"Accuracy: {:.5f}\".format(accuracy / len(input_5)))\n",
        "    print(\"-\"*30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint  10\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([   85,   344,   180,  ..., 16930, 18894,  2463])\n",
            "85\n",
            "tensor([   43,     4,    63,  ...,  5244,  1121, 16930])\n",
            "43\n",
            "tensor([  590,    88,     4,  ..., 17522,  7303, 16930])\n",
            "590\n",
            "tensor([    4,   180,    43,  ..., 14369, 14378, 16930])\n",
            "4\n",
            "tensor([  396,    68,    13,  ..., 17568, 16930,  5365])\n",
            "396\n",
            "tensor([    1,  1008,    68,  ..., 16193, 14378, 16930])\n",
            "1\n",
            "tensor([    2,     1,    13,  ..., 10037, 19440, 11336])\n",
            "2\n",
            "tensor([    2,     1,    13,  ..., 10037, 19440, 11336])\n",
            "2\n",
            "tensor([    2,     1,    13,  ..., 10037, 19440, 11336])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'し', 'て', 'い', 'た', 'のに', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  20\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([   85,   956,   143,  ..., 17588,  2463, 18319])\n",
            "85\n",
            "tensor([   43,     4,   685,  ..., 18864,  1121, 16930])\n",
            "43\n",
            "tensor([  590,    88,   180,  ...,  7303, 16930, 18027])\n",
            "590\n",
            "tensor([    4,    43,   180,  ..., 19465, 14378, 16930])\n",
            "4\n",
            "tensor([  396,    68,    13,  ...,  8629, 16930,  5365])\n",
            "396\n",
            "tensor([    1,  1008,    56,  ...,  8379, 14378, 16930])\n",
            "1\n",
            "tensor([    2,     1,    13,  ..., 11238, 19440,  9900])\n",
            "2\n",
            "tensor([    2,     1,    13,  ...,  9878, 11238,  9900])\n",
            "2\n",
            "tensor([    2,     1,    13,  ...,  9878, 11238,  9900])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'し', 'て', 'い', 'た', 'のに', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  30\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,   242,     4,  ...,  5886, 12160, 15707])\n",
            "143\n",
            "tensor([ 1942,    56,   110,  ..., 14169, 17249,  9582])\n",
            "1942\n",
            "tensor([  588,   180,   590,  ..., 18319,  8051, 17559])\n",
            "588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([   43,   180,   586,  ..., 19151, 18894, 17559])\n",
            "43\n",
            "tensor([    1,    36,    68,  ..., 17559,  5886,  6056])\n",
            "1\n",
            "tensor([    2,     1,    13,  ..., 13474, 19440, 16694])\n",
            "2\n",
            "tensor([    2,     1,    36,  ..., 11238, 19440, 16694])\n",
            "2\n",
            "tensor([    2,     1,    36,  ..., 11238, 19440, 16694])\n",
            "2\n",
            "tensor([    2,     1,    36,  ..., 11238, 19440, 16694])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', '暇', 'なく', 'て', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  40\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,   242,     4,  ..., 14060, 12160, 15707])\n",
            "143\n",
            "tensor([  110,    56,  1942,  ...,  2194, 17249,  2219])\n",
            "110\n",
            "tensor([   27,   535,   590,  ...,  5528, 18414,  6139])\n",
            "27\n",
            "tensor([    1,    36,    68,  ...,  8077,  6056, 14378])\n",
            "1\n",
            "tensor([    2,     1,    68,  ..., 17468,  8151, 16694])\n",
            "2\n",
            "tensor([    2,    36,     1,  ..., 17468,  7932, 16694])\n",
            "2\n",
            "tensor([    2,    36,     1,  ..., 17468,  7932, 16694])\n",
            "2\n",
            "tensor([    2,     1,    36,  ...,   345,  7932, 16694])\n",
            "2\n",
            "tensor([    2,     1,    36,  ...,   345,  7932, 16694])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', 'なら', '離婚', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  50\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,   242,  4679,  ...,  8604, 15707, 12160])\n",
            "143\n",
            "tensor([   56,  1942,   110,  ...,  2125,  2219, 17249])\n",
            "56\n",
            "tensor([ 5663,    13,  1722,  ...,  2194, 15707,     1])\n",
            "5663\n",
            "tensor([ 138, 3747,   43,  ..., 7291, 2039,    1])\n",
            "138\n",
            "tensor([ 3092,    18, 11228,  ...,  8316,  2335,  3750])\n",
            "3092\n",
            "tensor([    4,     1,    43,  ...,  3045,   423, 11833])\n",
            "4\n",
            "tensor([    1,    13,  1008,  ...,  2239,  6794, 15306])\n",
            "1\n",
            "tensor([   2,   36,    1,  ..., 7932, 1839,  314])\n",
            "2\n",
            "tensor([    2,    36,     1,  ..., 16694,  7932,   314])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', 'よ', 'け', 'ず', '跡', 'た', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  60\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,  4679,     4,  ..., 13598, 12160, 15707])\n",
            "143\n",
            "tensor([   56,   110,  1942,  ..., 17249,  2219,     1])\n",
            "56\n",
            "tensor([  13, 1722, 5663,  ..., 2194, 7533,    1])\n",
            "13\n",
            "tensor([8332,  540, 4630,  ..., 2654,  685,    4])\n",
            "8332\n",
            "tensor([5022,  224,  127,  ..., 3530,    4, 6419])\n",
            "5022\n",
            "tensor([    1,    25,   244,  ...,  5114,   742, 10680])\n",
            "1\n",
            "tensor([   2,    1,   41,  ..., 5421, 1839, 8151])\n",
            "2\n",
            "tensor([    2,     1,    68,  ..., 11396,  2303,  5421])\n",
            "2\n",
            "tensor([   2,    1,   68,  ..., 7932, 2303, 5421])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', 'よ', 'の', 'そば', 'なぁ', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  70\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,  4679,   242,  ..., 12160, 14060, 15707])\n",
            "143\n",
            "tensor([  566,   110,    56,  ..., 17249,  2219,     1])\n",
            "566\n",
            "tensor([  163,    56,   566,  ..., 20284,   885,  4132])\n",
            "163\n",
            "tensor([  13,   25,    7,  ..., 5186, 3328, 7917])\n",
            "13\n",
            "tensor([    1,   127,    25,  ...,  4231,  7498, 14718])\n",
            "1\n",
            "tensor([   2,    1,   25,  ..., 8410,  917, 1839])\n",
            "2\n",
            "tensor([    2,     1,    25,  ...,  5421, 16694,   314])\n",
            "2\n",
            "tensor([    2,     1,    25,  ...,  5421,   314, 16694])\n",
            "2\n",
            "tensor([    2,     1,    25,  ...,  7932,   314, 16694])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', '時', 'だけ', 'の', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  80\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  242,  4679,     4,  ..., 12160,  4411, 15707])\n",
            "242\n",
            "tensor([    4,  1591, 11283,  ..., 17862,  5186,  1055])\n",
            "4\n",
            "tensor([  342,   216,   566,  ..., 10803,   187,    41])\n",
            "342\n",
            "tensor([   18,   306,     7,  ...,  7031,  6596, 19490])\n",
            "18\n",
            "tensor([   25,     1,    36,  ..., 19490,  5699,   345])\n",
            "25\n",
            "tensor([    1,  1292,   395,  ...,  1447, 15649, 15403])\n",
            "1\n",
            "tensor([   2,    1,   13,  ..., 8151, 6472, 5421])\n",
            "2\n",
            "tensor([   2,   68,   18,  ...,  314, 7932, 5421])\n",
            "2\n",
            "tensor([   2,   68,   18,  ...,  314, 7932, 5421])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', '忘れ', 'た', '恋', 'に', 'は', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint  90\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  143,   242,   800,  ...,  4411, 15707, 12160])\n",
            "143\n",
            "tensor([ 566,   56,  395,  ..., 8949,    1, 2219])\n",
            "566\n",
            "tensor([ 566,  544,   56,  ..., 3888, 6306, 4132])\n",
            "566\n",
            "tensor([   13,   224,    68,  ..., 17993, 13474,  6306])\n",
            "13\n",
            "tensor([    1,  1008,    25,  ...,  6981, 15872,  4231])\n",
            "1\n",
            "tensor([    2,    36,     1,  ..., 14875,  2650,   917])\n",
            "2\n",
            "tensor([    2,    36,    68,  ...,  6188, 16694,   314])\n",
            "2\n",
            "tensor([    2,    36,    68,  ...,  6188, 16694,   314])\n",
            "2\n",
            "tensor([    2,    36,    68,  ...,  6188, 16694,   314])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', 'する', '時', '時', 'の', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n",
            "Checkpoint 100\n",
            "------------------------------\n",
            "['５年', '振り']\n",
            "tensor([  242,   800,   143,  ..., 12160,  4411,    41])\n",
            "242\n",
            "tensor([    4, 11283,  1591,  ...,  1427, 15757,  1055])\n",
            "4\n",
            "tensor([344, 342, 341,  ..., 382, 187,  41])\n",
            "344\n",
            "tensor([  18,   25,  306,  ..., 4455,  684, 1954])\n",
            "18\n",
            "tensor([   25,    68,     1,  ..., 12730,   885,  1058])\n",
            "25\n",
            "tensor([    1,  2884,  5036,  ...,  3759,  1462, 17025])\n",
            "1\n",
            "tensor([    2,     1,    25,  ..., 11490,  6472,  8410])\n",
            "2\n",
            "tensor([    2,     1,    68,  ...,   345, 16694,  7932])\n",
            "2\n",
            "tensor([    2,     1,    68,  ...,   345, 16694,  7932])\n",
            "2\n",
            "['<bos>', '家出', 'の', '兄', 'が', '<eos>'] ['<bos>', '忘れ', 'た', '君', 'に', 'は', '<eos>']\n",
            "Accuracy: 0.00000\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8XyeH2dw4zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainでは学習できてそう、末尾の2を切ろう"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}